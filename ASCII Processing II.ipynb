{
 "metadata": {
  "name": "",
  "signature": "sha256:ad3d83db2f7a338cdabfa342d1d8ffb6b5486be7c2d90c5940fd01a675b2a6b2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# ASCII Processing Two, Parallelization\n",
      "\n",
      "### Theodore Barnhart | Created: 20150120"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import glob\n",
      "import sys\n",
      "from IPython.display import display, clear_output\n",
      "import ProgressBar as pb\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Find forcing data for each flux file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "foo = pd.read_pickle('./forcing_fluxes_filenames.dataframe')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "actual_forcing = foo.loc[foo['exists']==True,'forcing']\n",
      "actual_fluxes = foo.loc[foo['exists']==True,'flux']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Now there are forcing files for each flux file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Define a function to parse both the flux and forcing files\n",
      "\n",
      "### Forcing Files Header:\n",
      "\n",
      "- P : Precipitation [mm]\n",
      "- Tmax : Maximum Daily Temperature [C]\n",
      "- Tmin : Minimum Daily Temperature [C]\n",
      "- W : Wind Speed [m/s]\n",
      "\n",
      "### Fluxes Files Header:\n",
      "\n",
      "- y : Year\n",
      "- m : month\n",
      "- d : day\n",
      "- ET : Total ET [mm]\n",
      "- R : Runoff [mm]\n",
      "- BF : Baseflow [mm]\n",
      "- sm1 : Soil Moisture Level 1 [mm]\n",
      "- sm2 : Soil Moisture Level 2 [mm]\n",
      "- sm3 : Soil Moisture Level 3 [mm]\n",
      "- SWE : Snow Water Equivalent [mm]\n",
      "- Cs : Canopy Storage [mm]\n",
      "- Qs : Sensible Heat Flux [W/m$^2$]\n",
      "- Ql : Latent Heat Flux [W/m$^2$]\n",
      "- Qg : Ground Heat Flux [W/m$^2$]\n",
      "- NR : Net Radiation [W/m$^2$] \n",
      "- PEText : PET for existing vegetation [mm]\n",
      "- PETtrc : PET for tall reference crop [mm]\n",
      "- PETsrc : PET for short reference crop [mm]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parsevic(fr,fx):\n",
      "    forcing_columns = ['P','Tmax','Tmin','W']\n",
      "    fluxes_columns = ['y','m','d','ET','R','BF','sm1','sm2','sm3','SWE','Cs','Qs','Ql','Qg','NR','PEText','PETtrc','PETsrc']\n",
      "    \n",
      "    # get indexing information \n",
      "    frlat = float(fr.split('_')[-2]) # extract latitude from file name\n",
      "    frlon = float(fr.split('_')[-1]) # extract longitude from file name\n",
      "    \n",
      "    ## load the forcing data\n",
      "    force = pd.read_table(fr, sep=' ', names=forcing_columns)\n",
      "    force.index = pd.DatetimeIndex(dates)\n",
      "    \n",
      "    # calculate long term average P\n",
      "    P = force.P.sum()/n\n",
      "    \n",
      "    ##### compute the snow fraction \n",
      "    force['coef'] = (0.-force.Tmin)/(np.abs(force.Tmax-force.Tmin))\n",
      "    \n",
      "    force.loc[force.coef<0,'coef'] = 0.\n",
      "    force.loc[force.coef>1,'coef'] = 1.\n",
      "    \n",
      "    force['snow'] = force.P*force.coef\n",
      "    \n",
      "    # compute the long term average Snow fraction\n",
      "    Sf = force.snow.sum()/force.P.sum()\n",
      "    \n",
      "    ## load the flux data\n",
      "    flux = pd.read_table(fx, sep='\\t', names=fluxes_columns)\n",
      "    flux.index = pd.DatetimeIndex(dates)\n",
      "        \n",
      "    # compute the long term average ET\n",
      "    ET = flux.ET.sum()/n\n",
      "    \n",
      "    PETpenmanvic = flux.PEText.sum()/n\n",
      "    \n",
      "    del force\n",
      "    del flux\n",
      "    \n",
      "    return frlat,frlon,P,Sf,ET,PETpenmanvic\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import IPython.parallel as p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# connect with the engines on the cluster\n",
      "cp = p.Client()\n",
      "cp.block=False\n",
      "cp.ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "[0, 1, 2, 3, 4, 5]"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "view = cp.load_balanced_view() # generate a load balanced view"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px # import cell onto all engines\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "dates = pd.read_pickle('/Volumes/Users/Theo/projects/Budyko_vic/timecode.pcl')\n",
      "n = len(dates)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = view.map(parsevic,actual_forcing,actual_fluxes) # map function and input to engines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# simple progress bar\n",
      "prog = pb.ProgressBar(len(actual_fluxes))\n",
      "\n",
      "while res.ready() == False:\n",
      "    prog.animate(res.progress)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "<AsyncMapResult: finished>"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "frlat,frlon,P,Sf,ET,PETpenmanvic = zip(*res.result) # extract results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# translate results into arrays\n",
      "frlat = np.array(frlat)\n",
      "frlon = np.array(frlon)\n",
      "P = np.array(P)\n",
      "Sf = np.array(Sf)\n",
      "ET = np.array(ET)\n",
      "PETpenmanvic = np.array(PETpenmanvic)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# save results\n",
      "np.savez_compressed('./new_budyko_data.npz',frlat=frlat,frlon=frlon,P=P,Sf=Sf,ET=ET,PETpenmanvic=PETpenmanvic)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    }
   ],
   "metadata": {}
  }
 ]
}