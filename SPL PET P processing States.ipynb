{
 "metadata": {
  "name": "",
  "signature": "sha256:42a7eaaf77562ef22f31cacfc98cc0f3945e56d28ef857b4f6bec6c4a616f0cb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "from IPython import parallel as p\n",
      "import ProgressBar as pb"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "cp = p.Client()"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "cp.ids"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "view = cp.direct_view()"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "%%px\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "dates = pd.read_pickle('/Volumes/Users/Theo/projects/Budyko_vic/timecode.pcl')\n",
      "wyears = np.load('/Volumes/Users/Theo/projects/Budyko_vic/wyears.npy')\n",
      "fluxes_columns = ['y','m','d','ET','R','BF','sm1','sm2','sm3','SWE','Cs','Qs','Ql','Qg','NR','PEText','PETtrc','PETsrc']\n",
      "forcing_columns = ['P','Tmax','Tmin','W']"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import glob\n",
      "import ProgressBar as pb\n",
      "dates = pd.read_pickle('./timecode.pcl')\n",
      "wyears = np.load('./wyears.npy')\n",
      "fluxes_columns = ['y','m','d','ET','R','BF','sm1','sm2','sm3','SWE','Cs','Qs','Ql','Qg','NR','PEText','PETtrc','PETsrc']\n",
      "forcing_columns = ['P','Tmax','Tmin','W']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "def petp(lat,lon):\n",
      "    \n",
      "    # generate file names for Ullr\n",
      "    fl = '/Users/barnhatb/research/vic/fluxes/ascii/latitude.'+str(lat)+'/flux_snow_'+str(lat)+'_'+str(lon)\n",
      "    fr = '/Users/barnhatb/research/vic/forcing/ascii/latitude.'+str(lat)+'/Meteorology_Livneh_NAmerExt_15Oct2014_'+str(lat)+'_'+str(lon)\n",
      "    \n",
      "    # load the fluxes data\n",
      "    flux = pd.read_table(fl, sep='\\t', names=fluxes_columns)\n",
      "    flux.index = pd.DatetimeIndex(dates)\n",
      "\n",
      "    ## load the forcing data\n",
      "    force = pd.read_table(fr, sep=' ', names=forcing_columns)\n",
      "    force.index = pd.DatetimeIndex(dates)\n",
      "    \n",
      "    # grab only the days needed \n",
      "    flux = flux.loc['1998-01-01':'2013-12-31',:]\n",
      "    force = force.loc['1998-01-01':'2013-12-31',:]\n",
      "    \n",
      "    P = list(force.P.as_matrix())\n",
      "    PET = list(flux.PEText.as_matrix())\n",
      "    days = list(force.index)\n",
      "    \n",
      "    return lat,lon,days,P,PET\n",
      "    \n",
      "    #for day in flux.index:\n",
      "    #    return lat,lon,day,flux.loc[day,'PEText'],force.loc[day,'P']"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with np.load('./spl_domain.npz') as data:\n",
      "    lat = data['lat']\n",
      "    lon = data['lon']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lat = lat[lon <= -106]\n",
      "lon = lon[lon <= -106]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(lat)\n",
      "print len(lon)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 0\n",
      "fl = '/Users/barnhatb/research/vic/fluxes/ascii/latitude.'+str(lat[i])+'/flux_snow_'+str(lat[i])+'_'+str(lon[i])\n",
      "fr = '/Users/barnhatb/research/vic/forcing/ascii/latitude.'+str(lat[i])+'/Meteorology_Livneh_NAmerExt_15Oct2014_'+str(lat[i])+'_'+str(lon[i])\n",
      "\n",
      "flux = pd.read_table(fl, sep='\\t', names=fluxes_columns)\n",
      "flux.index = pd.DatetimeIndex(dates)\n",
      "\n",
      "flux = flux.loc['1998-01-01':'2013-12-31',:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = len(flux)\n",
      "print n\n",
      "\n",
      "m = len(lat)\n",
      "print m\n",
      "\n",
      "q = m*n\n",
      "print q\n",
      "\n",
      "\n",
      "\n",
      "# preallocate\n",
      "days = np.zeros([q])\n",
      "days[:] = np.NaN\n",
      "PET = days.copy()\n",
      "P = days.copy()\n",
      "\n",
      "strtct = 0\n",
      "ndct = strtct\n",
      "\n",
      "p = pb.ProgressBar(q)\n",
      "\n",
      "for i in xrange(m):\n",
      "\n",
      "    # generate file names for Ullr\n",
      "    fl = '/Users/barnhatb/research/vic/fluxes/ascii/latitude.'+str(lat[i])+'/flux_snow_'+str(lat[i])+'_'+str(lon[i])\n",
      "    fr = '/Users/barnhatb/research/vic/forcing/ascii/latitude.'+str(lat[i])+'/Meteorology_Livneh_NAmerExt_15Oct2014_'+str(lat[i])+'_'+str(lon[i])\n",
      "    \n",
      "    # load the fluxes data\n",
      "    flux = pd.read_table(fl, sep='\\t', names=fluxes_columns)\n",
      "    flux.index = pd.DatetimeIndex(dates)\n",
      "\n",
      "    ## load the forcing data\n",
      "    force = pd.read_table(fr, sep=' ', names=forcing_columns)\n",
      "    force.index = pd.DatetimeIndex(dates)\n",
      "    \n",
      "    # grab only the days needed \n",
      "    flux = flux.loc['1998-01-01':'2013-12-31',:]\n",
      "    force = force.loc['1998-01-01':'2013-12-31',:]\n",
      "    \n",
      "    #days.extend(flux.index)\n",
      "    #PET.extend(list(flux.PEText.as_matrix()))\n",
      "    #P.extend(list(force.P.as_matrix()))\n",
      "    \n",
      "    ndct = strtct + len(flux)\n",
      "    \n",
      "    days[strtct:ndct] = flux.index.to_julian_date()\n",
      "    PET[strtct:ndct] = flux.PEText.as_matrix() \n",
      "    P[strtct:ndct] = force.P.as_matrix()\n",
      "    \n",
      "    strtct = ndct+1\n",
      "    \n",
      "    #for day in flux.index:\n",
      "    #    days[ct] = day.to_julian_date()\n",
      "    #    PET[ct] = flux.loc[day,'PEText']\n",
      "    #    P[ct] = force.loc[day,'P']\n",
      "    #    ct += 1\n",
      "    p.animate(ndct)\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(P)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savez_compressed('./spl_cals',days=days,PET=PET,P=P)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "res = view.map(petp,lat[0:100],lon[0:100])"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "res.ready()"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "res.result"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}