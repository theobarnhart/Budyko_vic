{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = ['HUC_02','GAGE_ID','GAGE_NAME','LATITUDE','LONGITUDE','ELEVATION']\n",
    "gauges = pd.read_table('/Volumes/data/basin_dataset_public/basin_metadata/gauge_information.txt',usecols=[0,1,2,3,4,5],names=names,skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basins = pd.read_table('/Volumes/data/basin_dataset_public/basin_metadata/basin_physical_characteristics.txt',delim_whitespace=True,skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "streamfiles = glob.glob('/Volumes/data/basin_dataset_public/usgs_streamflow/*/*.txt') # grab all the streamflow records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Streamflow records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Data Frames\n",
    "data = pd.DataFrame(columns=['year','Q','gage']) # this will be Q by watershed and year\n",
    "data2 = pd.DataFrame(columns=['Q','gage']) # this will be the total Q for each watershed\n",
    "\n",
    "# define the header\n",
    "header=['basin','year','month','day','Q','Qual']\n",
    "\n",
    "# loop through each streamflow file\n",
    "for fl in streamfiles:\n",
    "    gage = int(fl.split('/')[-1].split('.')[0].split('_')[0]) # grab the gage ID from the file name\n",
    "    dat = pd.read_table(fl,delim_whitespace=True,names=header) # read in the file\n",
    "    \n",
    "    dat.Q*=86400. # multiply by the number of seconds in the day to get the total volume [CF]\n",
    "    dat.Q *= 0.0283168 #convert CF to cubic meters [m3]\n",
    "    \n",
    "    dat2 = dat.groupby(by='year').sum() # generate yearly sums\n",
    "    \n",
    "    dat2.reset_index(inplace=True) # this pulls the years out of the index to the column\n",
    "    n = len(dat2) # get the length of the annual data\n",
    "    dat2['gage'] = np.repeat(gage,n) # create a column of the gage ID\n",
    "    data = data.append(dat2[['year','Q','gage']]) # Save the yearly data to the yearly data frame\n",
    "    \n",
    "    # save the summed data for this watershed\n",
    "    dat3 = pd.DataFrame({'Q':dat.Q.sum(),'gage':gage},index=[0]) # generate long term Q sum in m3\n",
    "    data2 = data2.append(dat3) # save the cumulative data to the cumulative data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Streamflow Volumes to absolute discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing = [] # make a missing data list\n",
    "for gage in np.unique(data.gage):\n",
    "    if basins.loc[basins.BASIN_ID==gage].empty:\n",
    "        missing.append(gage) # if a basin is missing, add it to this list\n",
    "    else: # otherwise\n",
    "        area = basins.loc[basins.BASIN_ID==gage,'Size(km2)'].as_matrix() # pull the basin area from the basins data frame\n",
    "        area *= 1000000. # convert from km2 to m2\n",
    "        \n",
    "        # change the yearly data\n",
    "        data.loc[data.gage==gage,'Q'] /= area # convert the discharge from m3 to m\n",
    "        data.loc[data.gage==gage,'Q'] *= 1000. # convert m to mm\n",
    "        \n",
    "        # change the cumulative data\n",
    "        data2.loc[data2.gage==gage,'Q'] /= area # convert the discharge from m3 to m\n",
    "        data2.loc[data2.gage==gage,'Q'] *= 1000. # convert m to mm\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove missing records from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for gage in missing:\n",
    "    data.loc[data.gage==gage,:] = np.NaN\n",
    "    data2.loc[data2.gage==gage,:] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.to_pickle('../data/processed_observed_streamflow.pcl')\n",
    "data2.to_pickle('../data/processed_observed_streamflow_sums.pcl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
