{
 "metadata": {
  "name": "",
  "signature": "sha256:6d07c5575cf9516ff8820d2a6584d7004e01f11118bcfaf01a7c5391e8989736"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython import parallel as p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pc = p.Client()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pc.ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "[0, 1]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "view = pc.load_balanced_view()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "dates = pd.read_pickle('/Volumes/Users/Theo/projects/Budyko_vic/timecode.pcl')\n",
      "wyears = np.load('/Volumes/Users/Theo/projects/Budyko_vic/wyears.npy')\n",
      "fluxes_columns = ['y','m','d','ET','R','BF','sm1','sm2','sm3','SWE','Cs','Qs','Ql','Qg','NR','PEText','PETtrc','PETsrc']\n",
      "forcing_columns = ['P','Tmax','Tmin','W']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import glob\n",
      "\n",
      "dates = pd.read_pickle('./timecode.pcl')\n",
      "wyears = np.load('./wyears.npy')\n",
      "fluxes_columns = ['y','m','d','ET','R','BF','sm1','sm2','sm3','SWE','Cs','Qs','Ql','Qg','NR','PEText','PETtrc','PETsrc']\n",
      "forcing_columns = ['P','Tmax','Tmin','W']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def snowmeltflux(fl):\n",
      "    lat = float(fl.split('_')[-2]) # extract latitude from file name\n",
      "    lon = float(fl.split('_')[-1]) # extract longitude from file name\n",
      "\n",
      "    # load the fluxes data\n",
      "    flux = pd.read_table(fl, sep='\\t', names=fluxes_columns)\n",
      "    flux.index = pd.DatetimeIndex(dates)\n",
      "    \n",
      "    flux['melt'] = np.NaN # preallocate the melt column\n",
      "    #offset = pd.datetools.timedelta(1)\n",
      "    \n",
      "    s1 = flux.SWE[0:-1].as_matrix()\n",
      "    s2 = flux.SWE[1:].as_matrix()\n",
      "    \n",
      "    melt = s1-s2 # calculate melt\n",
      "    \n",
      "    melt = np.append(0,melt) # append a zero to the front b/c there can be no melt on that first day.\n",
      "    \n",
      "    melt[melt<0] = np.NaN\n",
      "    #print 'df length',len(flux)\n",
      "    #print 'melt length',len(melt)\n",
      "    \n",
      "    flux.melt = melt\n",
      "    \n",
      "    flux['netSM'] = flux.melt-flux.ET\n",
      "    \n",
      "    #for day in flux.index[1:-1]:\n",
      "    #    flux.loc[day,'melt'] = flux.loc[day-offset ,'SWE'] - flux.loc[day,'SWE']\n",
      "    \n",
      "    flux.loc[flux.netSM < 0,'netSM'] = 0. # if snowmelt is negative (accumulatoion) then zero it\n",
      "    \n",
      "    smlength = len(flux.loc[flux.netSM > 0,:].netSM) # get the number of days where netSM is greater than 0\n",
      "    \n",
      "    if smlength > 0.:\n",
      "        smelt = flux.loc[flux.netSM > 0,:].netSM.sum()/smlength # compute long term average daily snowmelt\n",
      "    else:\n",
      "        smelt = 0.\n",
      "        \n",
      "    return lat,lon,smelt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "fl = files.flux[300000]\n",
      "\n",
      "lat = float(fl.split('_')[-2]) # extract latitude from file name\n",
      "lon = float(fl.split('_')[-1]) # extract longitude from file name\n",
      "\n",
      "# load the fluxes data\n",
      "flux = pd.read_table(fl, sep='\\t', names=fluxes_columns)\n",
      "flux.index = pd.DatetimeIndex(dates)\n",
      "\n",
      "flux['melt'] = np.NaN # preallocate the melt column\n",
      "#offset = pd.datetools.timedelta(1)\n",
      "\n",
      "s1 = flux.SWE[0:-1].as_matrix()\n",
      "s2 = flux.SWE[1:].as_matrix()\n",
      "\n",
      "melt = s1-s2\n",
      "\n",
      "melt = np.append(0,melt)\n",
      "\n",
      "melt[melt<0] = np.NaN\n",
      "#print 'df length',len(flux)\n",
      "#print 'melt length',len(melt)\n",
      "\n",
      "flux.melt = melt\n",
      "\n",
      "flux['netSM'] = flux.melt-flux.ET\n",
      "\n",
      "#for day in flux.index[1:-1]:\n",
      "#    flux.loc[day,'melt'] = flux.loc[day-offset ,'SWE'] - flux.loc[day,'SWE']\n",
      "\n",
      "flux.loc[flux.netSM < 0,'netSM'] = 0. # if snowmelt is negative (accumulatoion) then zero it\n",
      "\n",
      "smlength = len(flux.loc[flux.netSM > 0,:].netSM)\n",
      "\n",
      "if smlength > 0.:\n",
      "    smelt = flux.loc[flux.netSM > 0,:].netSM.sum()/smlength # compute long term average daily snowmelt\n",
      "else:\n",
      "    smelt = 0.\n",
      "    \n",
      "print round(smelt,3),'mm/d'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7.937 mm/d\n",
        "CPU times: user 69.3 ms, sys: 10.6 ms, total: 79.9 ms\n",
        "Wall time: 228 ms\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "files = pd.read_pickle('./forcing_fluxes_filenames_lat_lon_index.df')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = view.map(snowmeltflux,files.flux) # map the function across the engines to the files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ProgressBar as pb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prog = pb.ProgressBar(len(files.forcing))\n",
      "\n",
      "while res.ready() == False:\n",
      "    prog.animate(res.progress)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "[                  0%                  ]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4202 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4207 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4213 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4218 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4223 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4229 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4235 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4241 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4246 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4251 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4256 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4263 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4271 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4279 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4284 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4290 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4296 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4304 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4310 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4315 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4320 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4328 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4334 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4341 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4348 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4356 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4362 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4368 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4376 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4379 of 309673 complete"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \r",
        "[                  1%                  ]  4384 of 309673 complete"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res.ready()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lat,lon,netSM = zip(*res.result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savez_compressed('./net_snowmelt.npz',lat=lat,lon=lon,netSM=netSM)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}